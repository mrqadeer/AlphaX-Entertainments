{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PROMPT = \"\"\"\n",
    "YOU ARE AN EXPERT IN FILM AND MEDIA RECOGNITION, TASKED WITH IDENTIFYING MOVIES, SERIES, AND DRAMAS BASED ON USER {INPUT}. YOUR TASK IS TO:\n",
    "1. IDENTIFY THE CORRECT MEDIA TITLE FROM THE USER IMAGE.THE IMAGE MAY CONTAINS A SINGLE STAR OF MEDIA OR THE MULTIPLE STARS OF MEDIA OR ONE IMGAGE OF SCENE IN THE MEDIE.\n",
    "2. RETURN A DETAILED RESPONSE IN JSON FORMAT INCLUDING TITLE, GENRE, CAST, DIRECTOR, RELEASE DATE, IMDb RATING, IMDb VOTES, IMDb URL, POSTER URL, AND RUN TIME.\n",
    "3. PROVIDE A LIST OF RECOMMENDED SIMILAR MEDIA BASED ON THE MEDIA'S GENRE AND OTHER CHARACTERISTICS.\n",
    "\n",
    "### INSTRUCTIONS:\n",
    "- TRANSLATE THE DIALOGUE INTO ENGLISH IF IT IS NOT IN ENGLISH.\n",
    "- PROCESS THE USER INPUT TO IDENTIFY THE MEDIA TITLE AND ENSURE IT IS ACCURATE.\n",
    "- RETRIEVE RELEVANT INFORMATION FROM TRUSTED SOURCES LIKE IMDb.\n",
    "- PROVIDE A LIST OF 10 SIMILAR MEDIA, WITH EACH RECOMMENDATION INCLUDING A TITLE AND IMDb URL.\n",
    "- RETURN THE FINAL OUTPUT AS A JSON OBJECT.\n",
    "\n",
    "### CHAIN OF THOUGHT:\n",
    "\n",
    "1. **Understanding the User Input:**\n",
    "   - Extract the media title from the user's dialogue. For example, if the user says \"I really liked that series about a teacher who starts making drugs,\" infer the title as \"Breaking Bad.\"\n",
    "\n",
    "2. **Fetching Media Information:**\n",
    "   - Search for the correct media entry on IMDb.\n",
    "   - Extract the following details:\n",
    "     - Title\n",
    "     - Genre\n",
    "     - Cast (main actors)\n",
    "     - Director(s)\n",
    "     - Release Date\n",
    "     - IMDb Rating\n",
    "     - Number of IMDb Votes\n",
    "     - IMDb URL\n",
    "     - Poster URL\n",
    "     - Run Time\n",
    "   - Ensure the information is accurate and matches the media's official IMDb entry.\n",
    "\n",
    "3. **Generating Similar Media Recommendations:**\n",
    "   - BASED ON the genre, cast, or director of the recognized media, recommend at least ten (10) similar titles.\n",
    "   - FOR EACH RECOMMENDATION, PROVIDE:\n",
    "     - The correct title\n",
    "     - A valid IMDb URL (ensure the URL matches the title and directs to IMDb)\n",
    "     - DO NOT generate random recommendations or invalid URLs.\n",
    "\n",
    "### OUTPUT FORMAT:\n",
    "The final output should be formatted as a JSON object, following this structure:\n",
    "```json\n",
    "{\n",
    "    \"title\": \"Name of Movie/Series/Drama\",\n",
    "    \"genre\": \"Name of Genre\",\n",
    "    \"cast\": [\"Main Cast\"],\n",
    "    \"director\": [\"Name of Directors\"],\n",
    "    \"releaseDate\": \"Date of Release\",\n",
    "    \"imdb\": \"IMDb Rating\",\n",
    "    \"num_votes\": \"Number of IMDb Votes\",\n",
    "    \"imdb_url\": \"IMDb URL\",\n",
    "    \"poster\": \"Poster URL From IMDb Original Website\",\n",
    "    \"run_time\": \"Time of Runtime\",\n",
    "    \"recommendations\": [\n",
    "        {\"Title of Sequel or Similar Media 1\": \"IMDb URL\"},\n",
    "        {\"Title of Sequel or Similar Media 2\": \"IMDb URL\"},\n",
    "        {\"Title of Sequel or Similar Media 3\": \"IMDb URL\"}\n",
    "    ]\n",
    "}\n",
    "### WHAT NOT TO DO:\n",
    "DO NOT PROVIDE INCOMPLETE OR INCORRECT MEDIA DETAILS.\n",
    "DO NOT RETURN RECOMMENDATIONS UNRELATED TO THE GENRE OR CONTEXT OF THE MEDIA.\n",
    "DO NOT INVENT OR FABRICATE MEDIA DETAILS IF THEY CANNOT BE VERIFIED THROUGH TRUSTED SOURCES LIKE IMDb.\n",
    "DO NOT IGNORE THE SPECIFIED JSON FORMAT OR RETURN PARTIAL OUTPUT.\n",
    "DO NOT RETURN RECOMMENDATIONS WITHOUT PROVIDING CORRECT IMDb LINKS.\n",
    "###ERROR HANDLING:\n",
    "IF THE MEDIA TITLE IS UNCLEAR OR THE MODEL CANNOT FIND A MATCH, RETURN AN ERROR MESSAGE IN THE FOLLOWING FORMAT:\n",
    "\n",
    "{\n",
    "    \"error\": \"Unable to find media matching the description. Please provide more details or try a different query.\"\n",
    "}\n",
    "\n",
    "### Final Thoughts:\n",
    "- This prompt ensures that the model will consistently retrieve media details, genre, and cast while recommending similar media.\n",
    "- The **Chain of Thought** explicitly breaks down the task into smaller, manageable steps, improving accuracy and clarity in the results.\n",
    "- Following the format provided will guarantee that the response is always structured in a way that's easy to parse for further application development.\n",
    "\n",
    "Note:Return the response in this exact JSON format only. Do not include any additional text before or after the JSON response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\wave.py:649\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\wave.py:286\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\wave.py:253\u001b[0m, in \u001b[0;36mWave_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with RIFF id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWAVE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mError\u001b[0m: file does not start with RIFF id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:246\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as AIFF\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43maifc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAifc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:358\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:322\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile does not start with FORM id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    323\u001b[0m formdata \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mError\u001b[0m: file does not start with FORM id",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:272\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43maifc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43maiff_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:954\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAifc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:364\u001b[0m, in \u001b[0;36mAifc_read.__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# assume it is an open file object already\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\aifc.py:320\u001b[0m, in \u001b[0;36mAifc_read.initfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m file\n\u001b[1;32m--> 320\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[43mChunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mgetname() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFORM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\chunk.py:67\u001b[0m, in \u001b[0;36mChunk.__init__\u001b[1;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkname) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mEOFError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Use this transcribed text with your LLM\u001b[39;00m\n\u001b[0;32m     85\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording (11).mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 86\u001b[0m audio_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# audio_response = get_image_llm_response(llm, audio_text, \"text/plain\")\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# print(\"Audio Transcription Response:\", audio_response)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print(\"Audio response:\", audio_response)\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# # print(\"Video response:\", video_response)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 73\u001b[0m, in \u001b[0;36mtranscribe_audio_to_text\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_to_text\u001b[39m(audio_path):\n\u001b[0;32m     72\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[1;32m---> 73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:274\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(aiff_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (aifc\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n\u001b[1;32m--> 274\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# AIFF is a big-endian format\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader\u001b[38;5;241m.\u001b[39mgetnchannels() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio must be mono or stereo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format"
     ]
    }
   ],
   "source": [
    "\n",
    "import speech_recognition as sr\n",
    "import pathlib\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import httpx\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", max_tokens=4000)\n",
    "\n",
    "\n",
    "def get_image_llm_response(llm, media_data: str, media_type: str):\n",
    "    try:\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": IMAGE_PROMPT},\n",
    "                {\n",
    "                    \"type\": media_type,\n",
    "                    media_type: {\"url\": f\"data:{media_type};base64,{media_data}\"},\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        response = llm.invoke([message])\n",
    "\n",
    "        # Parse and clean up the response\n",
    "        response = response.content.strip().replace(\n",
    "            \"json\", \"\").replace(\"```\", \"\").replace('\\n', '')\n",
    "        # Optionally parse as JSON if needed\n",
    "        # response = ast.literal_eval(response)\n",
    "\n",
    "        return response\n",
    "    # except ChatGoogleGenerativeAIError as e:\n",
    "    #     # st.error(\"You are running out of credits. Check you qouta\")\n",
    "    #     st.error(f\"Error: {e}\")\n",
    "    #     raise e\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def read_audio(audio_path):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise FileNotFoundError(f\"The file at {audio_path} does not exist.\")\n",
    "\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            audio_data = base64.b64encode(audio_file.read()).decode(\"utf-8\")\n",
    "            return audio_data\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def read_video(video_path):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"The file at {video_path} does not exist.\")\n",
    "\n",
    "    try:\n",
    "        with open(video_path, \"rb\") as video_file:\n",
    "            video_data = base64.b64encode(video_file.read()).decode(\"utf-8\")\n",
    "            return video_data\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "# You will need to use an API or library for transcribing audio to text.\n",
    "# For example, using Google Speech-to-Text API:\n",
    "\n",
    "\n",
    "def transcribe_audio_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Audio could not be transcribed.\"\n",
    "        except sr.RequestError:\n",
    "            return \"API request failed.\"\n",
    "\n",
    "\n",
    "# Use this transcribed text with your LLM\n",
    "audio_path = str(pathlib.Path(\"Recording (11).mp3\"))\n",
    "audio_text = transcribe_audio_to_text(audio_path)\n",
    "# audio_response = get_image_llm_response(llm, audio_text, \"text/plain\")\n",
    "\n",
    "# print(\"Audio Transcription Response:\", audio_response)\n",
    "\n",
    "\n",
    "# video_path = \"video.mp4\"\n",
    "\n",
    "# # Get base64 encoded data for audio and video files\n",
    "# # audio_data = read_audio(audio_path)\n",
    "# video_data = read_video(video_path)\n",
    "\n",
    "# # Now you can pass the base64 data to your LLM\n",
    "# audio_response = get_image_llm_response(llm, video_data, \"audio/mpeg\")\n",
    "# # video_response = get_image_llm_response(llm, video_data, \"video/mp4\")\n",
    "\n",
    "# print(\"Audio response:\", audio_response)\n",
    "# # print(\"Video response:\", video_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: Mujhe recording chahie I want to get recording Mujhe recording aur Sara Kuchh chahie\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "\n",
    "def convert_mp3_to_wav(mp3_path):\n",
    "    \"\"\"Convert mp3 file to wav format.\"\"\"\n",
    "    # Ensure mp3_path is a string (if pathlib.Path object is passed, convert it to a string)\n",
    "    if isinstance(mp3_path, pathlib.Path):\n",
    "        mp3_path = str(mp3_path)\n",
    "\n",
    "    try:\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "        wav_path = mp3_path.replace(\".mp3\", \".wav\")\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        return wav_path\n",
    "    except Exception as e:\n",
    "        return f\"Error converting mp3 to wav: {e}\"\n",
    "\n",
    "\n",
    "def transcribe_audio_to_text(audio_path):\n",
    "    \"\"\"Transcribe a WAV audio file to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            # Try to transcribe the audio using Google Web Speech API\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Audio could not be transcribed.\"\n",
    "            except sr.RequestError:\n",
    "                return \"API request failed.\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Audio file not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "# file = st.file_uploader(\"Upload your audio file\")\n",
    "# Example usage:\n",
    "mp3_path = pathlib.Path(\"Recording (11).mp3\")\n",
    "\n",
    "# # Convert MP3 to WAV\n",
    "wav_path = convert_mp3_to_wav(mp3_path)\n",
    "\n",
    "if os.path.exists(wav_path):\n",
    "    # Transcribe the WAV file\n",
    "    audio_text = transcribe_audio_to_text(wav_path)\n",
    "    print(\"Transcription:\", audio_text)\n",
    "else:\n",
    "    print(wav_path)  # Error message if conversion failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\images\\\\downloaded.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/images/downloaded.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtouch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Read the local image and encode it to base64\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m image_file:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\pathlib.py:1303\u001b[0m, in \u001b[0;36mPath.touch\u001b[1;34m(self, mode, exist_ok)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok:\n\u001b[0;32m   1302\u001b[0m     flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mO_EXCL\n\u001b[1;32m-> 1303\u001b[0m fd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1304\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(fd)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\images\\\\downloaded.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pathlib\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import httpx\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCueuiotXQkFYMFOomScrTbi7rv7VgiVKc\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", max_tokens=4000)\n",
    "# Replace the URL image with a local image file\n",
    "# image_path = \"data/combined_frames_image.jpg\"\n",
    "image_path = r\"data/images/downloaded.png\"\n",
    "pathlib.Path(image_path).touch()\n",
    "# Read the local image and encode it to base64\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": IMAGE_PROMPT},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Invoke the model\n",
    "ai_msg = llm.invoke([message])\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded successfully: arya_stark_hbo.jpg\n",
      "Failed to download https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Arya_Stark-Maisie_Williams.jpg/1200px-Arya_Stark-Maisie_Williams.jpg: 404 Client Error: Not Found for url: https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Arya_Stark-Maisie_Williams.jpg/1200px-Arya_Stark-Maisie_Williams.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def download_image(url, save_as):\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, stream=True)\n",
    "        response.raise_for_status()  # Raises an error on a bad status\n",
    "        with open(save_as, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {save_as}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "\n",
    "image_url1 = \"https://static.hbo.com/content/dam/hbodata/series/game-of-thrones/character/s5/arya-stark-1920.jpg?w=1200\"\n",
    "# image_url2 = \"https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Arya_Stark-Maisie_Williams.jpg/1200px-Arya_Stark-Maisie_Williams.jpg\"\n",
    "image_url2 = \"\"\n",
    "# image_url2 = \"https://static.wikia.nocookie.net/gameofthrones/images/b/be/AryaShipIronThrone.PNG/revision/latest?cb=20190520174300\"\n",
    "\n",
    "save_as1 = \"arya_stark_hbo.jpg\"\n",
    "save_as2 = \"arya_stark.jpg\"\n",
    "\n",
    "download_image(image_url1, save_as1)\n",
    "download_image(image_url2, save_as2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded successfully: arya_stark_hbo.jpg\n",
      "Image downloaded successfully: arya_stark.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def download_image(url, save_as):\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, stream=True)\n",
    "        response.raise_for_status()  # Raises an error on a bad status\n",
    "        with open(save_as, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {save_as}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "\n",
    "image_url1 = \"https://static.hbo.com/content/dam/hbodata/series/game-of-thrones/character/s5/arya-stark-1920.jpg?w=1200\"\n",
    "image_url2 = \"https://upload.wikimedia.org/wikipedia/en/3/39/Arya_Stark-Maisie_Williams.jpg\"\n",
    "\n",
    "save_as1 = \"arya_stark_hbo.jpg\"\n",
    "save_as2 = \"arya_stark.jpg\"\n",
    "\n",
    "download_image(image_url1, save_as1)\n",
    "download_image(image_url2, save_as2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
